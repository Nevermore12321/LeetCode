[toc]


# deployment 的概念

pod 是不健壮的，而且pod本身是没有可再生性的，随时都会挂掉，这时：
- 如果需要pod数目很多，这时就需要ReplicaSet控制器来管理
- Pod是没有再生性的，如果某个pod挂掉后，这就需要控制器自动管理pod


## ReplicaSet (rs)控制器

**replicaSet 目的**：  
ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性


**replicaSet 工作原理**：  
replicaSet 通过下面的字段来控制和管理pod：
- 用来识别 Pod 集合的标签选择器
- 标明应该维护的副本个数
- 新创建pod的模板

replicaSet 现在的主要作用：
- 主要被Deployments 用作协调 Pod 创建、删除和更新的机制。 
- 当使用 Deployment 时，不必担心还要管理它们创建的 ReplicaSet。
- Deployment 会拥有并管理它们的 ReplicaSet。
- Deployment 管理 ReplicaSet，并向 Pod 提供声明式的更新以及许多其他有用的功能。
- 使用 Deployment 而不是直接使用 ReplicaSet


## ReplicationController (rc)控制器

注意：  
**现在推荐使用配置 ReplicaSet 的 Deployment 来建立副本管理机制。**

**ReplicationController作用:**  
ReplicationController 确保在任何时候都有特定数量的 Pod 副本处于运行状态。 换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的。


**ReplicationController 工作原理**：
- 当 Pod 数量过多时，ReplicationController 会终止多余的 Pod
- 当 Pod 数量太少时，ReplicationController 将会启动新的 Pod


# deployment 控制器

Deployment 控制器以受控速率更改实际状态， 使其变为期望状态。你可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment。



## 创建 deployment

模板为：
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: gsh
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

**说明**：
- deployment.metadata就表示 deployment 的元数据
- template 表示 创建 pod 的模板
- replicas : 表示创建pod的副本数
- selector : 表示 Deployment 如何查找要管理的 Pods，也就是通过这个selector来选择管理pod
    - matchLabels : {key,value} 偶对的映射，表示要选择的标签
    - 注意：**这里的标签一定要和pod的标签一致，这样才可以匹配并且管理**

注意：  
- 上面的 yaml 文件，也可以通过命令行生成：(通过 --dry-run 重定向)
```
kubectl create deployment web1 --image=nginx --replicas=6 --dry-run=client -o yaml > web-deployment.yaml
```


## deploymnet 的查看命令

1. 查看 deployment ：
    - `kubectl get deployments.apps`
    - `-o wide` 选项，查看详细信息
```
[root@k8s-master deployment]# kubectl get deployments.apps
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
web1   6/6     6            6           3m13s
[root@k8s-master deployment]# kubectl get deployments.apps -o wide
NAME   READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES   SELECTOR
web1   6/6     6            6           4m3s   nginx        nginx    app=nginx
```
2. 查看 Deployment 上线状态
    - `kubectl rollout status deployment web1`
```
[root@k8s-master deployment]# kubectl rollout status deployment web1
deployment "web1" successfully rolled out
```
3. 查看 Pod 自动生成的标签
    - `kubectl get pods --show-labels1`
```
[root@k8s-master deployment]# kubectl get pods --show-labels
NAME                    READY   STATUS    RESTARTS   AGE     LABELS
web1-6799fc88d8-5xlj8   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8
web1-6799fc88d8-64vvd   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8
web1-6799fc88d8-9j7kl   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8
web1-6799fc88d8-bbc4b   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8
web1-6799fc88d8-ltz4g   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8
web1-6799fc88d8-n842f   1/1     Running   0          6m23s   app=nginx,pod-template-hash=6799fc88d8

```

## 缩放 deployment ，也就是修改deployment的副本数

两种方式修改 deployment 的副本数：  
1. 通过命令行方式：
    - `kubectl scale deployment web1 --replicas=8`
    - `kubectl edit deployments.apps web1`
2. 通过修改 yaml 文件的方式，修改 replicas 字段后
    - `kubectl apply -f xx.yaml`

## HPA(horizontal pod autoscalers) 水平自动伸缩

**概念**
可以根据 CPU 利用率自动扩缩 ReplicationController、Deployment 或者 ReplicaSet 中的 Pod 数量 


**过程**：
- 假设 deployment 启动了 3 个pod副本，而每个副本的负载率比较低
- 当有大规模的 并发数 到来时，每个 pod 的负载使用率增大
- 假设 pod 的负载使用率，例如 cpu 使用率，会超过某个 阙值
- 当有 pod 超过 负载阈值后，就会新创建出pod来分担
- 通过检测pod CPU的负载，解决deployment里某pod负载太重，动态伸缩pod的数量来负载均衡
- HPA 就是来监控 pod 的负载使用情况，一旦超出 阈值，通知 deployment 来创建新的 pod 分担负载




**HPA 的使用**：
1. 创建 HPA
    - `kubectl autoscale deployment web1 --min=1 --max=10`
    - 说明，上面的命令创建了hpa，最少1个pod，最多只能创建10个pod
    - 默认的cpu 的负载率阈值为 80%
```
[root@k8s-master deployment]# kubectl autoscale deployment web1 --min=1 --max=10
horizontalpodautoscaler.autoscaling/web1 autoscaled
[root@k8s-master deployment]# kubectl get hpa
NAME   REFERENCE         TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
web1   Deployment/web1   <unknown>/80%   1         10        0          4s

```
2. 创建 HPA，并指定 cpu 的阈值
    - `kubectl autoscale deployment web1 --min=1 --max=10 --cpu-percent=50`
    - 说明，这里指定了 cpu 负载率 的阈值为 50%
```
[root@k8s-master deployment]# kubectl autoscale deployment web1 --cpu-percent=50 --min=1 --max=10
horizontalpodautoscaler.autoscaling/web1 autoscaled
[root@k8s-master deployment]# kubectl get hpa
NAME   REFERENCE         TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
web1   Deployment/web1   <unknown>/50%   1         10        0          4s

```
3. 注意，如果要使用 hpa，必须安装 metric server 来监控资源使用率
    - 解决当前cpu的使用量为unknown：
        - 在 metric server 的部署yaml 中添加：`- --metric-resolution=30s`
        ```
        command:
        - /metrics-server
        - --metric-resolution=30s
        - --kubelet-insecure-tls
        - --kubelet-preferred-address-types=InternalIP
        
        ```
        - 并且在 deployment 的yaml文件中，添加 deployment.spec.template.spec.containers.resources
        ```
        resources:
          requests:
            cpu: 400m
        ```
    - 结果：
    ```
    [root@k8s-master deployment]# kubectl get hpa
    NAME   REFERENCE         TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
    web1   Deployment/web1   0%/50%    1         10        6          16s
    
    ```
    
    
    

## deployment 健壮性测试

测试内容：
- 创建了一个deployment，并且启动了 3 个pod副本
- 其中 一个 pod 的副本在 node2 节点上，其余pod在node1节点上
- 如果 node2 突然宕机，那么在node2上的这个pod，会处于 Unknown 状态，并且 deployment 会新创建一个pod，来满足 3 个副本的要求
- 但未来某时刻，node2 恢复启动，该pod也不会重新启动在node2节点上，而是一直处于 Unknown 状态



## deployment 升级镜像


有三种形式，可以修改 deployment 的镜像：
1. 通过命令行的方式
    - 在线修改，通过 `kubectl edit deployments.apps web1`， 修改 image 字段
    - 通过命令修改，`kubectl set image 控制器类型 控制器名称 容器名=新的镜像名`
2. 修改 yaml 文件形式
    - 修改完 deployment 的yaml 文件后，通过 `kubectl apply -f xxx.yaml` 修改


**查看 deployment 的变更记录**：  
```
[root@k8s-master deployment]# kubectl rollout history deployment web1
deployment.apps/web1
REVISION  CHANGE-CAUSE
2         <none>
3         <none>
```

可以看到，**如果没有 加 --record 选项，就不会记录在变更历史中，kubectl apply 和 kubectl set image 命令都可以 加 --record=true选项**，如果加了 --record 选项，例如：
```
[root@k8s-master deployment]# kubectl set image deployment web1 nginx=nginx:1.7.9 --record=true
deployment.apps/web1 image updated
[root@k8s-master deployment]# kubectl rollout history deployment web1
deployment.apps/web1
REVISION  CHANGE-CAUSE
3         <none>
4         <none>
5         kubectl set image deployment web1 nginx=nginx:1.7.9 --record=true

```

可以看到 变更记录中已经有了升级命令。


** deployment 的回滚** ：
回滚命令：`kubectl rollout undo deployment web1 --to-revision=5`

例子：
```
[root@k8s-master deployment]# kubectl rollout undo deployment web1 --to-revision=5
deployment.apps/web1 rolled back
```

## deployment 的滚动升级

**滚动升级的概念：**
- 当升级 deployment 的镜像时，并不是所有的 pod 一下全部升级
- 而是 部分 pod 先升级，其余pod保持不变，当这部分pod升级完成后，其余pod在升级

**滚动升级的配置**：
- deployment.spec.strategy 字段用来配置滚动升级策略
- deployment.spec.strategy.type : 用新 Pods 替换旧 Pods 的策略, 可以是 RollingUpdate 或者 Recreate 
    - RollingUpdate : 默认值，采取 滚动更新的方式更新 Pods。你可以指定 maxUnavailable 和 maxSurge 来控制滚动更新 过程。
        - maxSurge : 在升级过程中一次升级几个
        - maxUnavailable : 在升级过程中，只能有1个不可用一次性删除多少个pod
    - Recreate : 在创建新 Pods 之前，所有现有的 Pods 会被杀死。


例如：
```
strategy:
rollingUpdate:
  maxSurge: 3
  maxUnavailable: 1
```