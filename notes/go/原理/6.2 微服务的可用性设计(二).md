# 限流

[toc]



## 简介

**限流：**是指在一段时间内，定义某个客户或应用可以接收或处理多少个请求的技术。

例如，
- 通过限流，你可以过滤掉产生流量峰值的客户和微服务
- 或者可以确保你的应用程序在自动扩展(Auto Scaling)失效前都不会出现过载的情况。

**之前提到的令牌桶、漏桶 针对单个节点，无法分布式限流。**

**为什么分布式限流：**
- QPS 限流
    - 不同的请求可能需要数量迥异的资源来处理。
    - 某种静态 QPS 限流不是特别准。
- 给每个用户设置限制
    - 全局过载发生时候，针对某些“异常”进行控制。
    - 一定程度的“超卖”配额。
- 按照优先级丢弃。
- 拒绝请求也需要成本。（例如 超过流量回复 429 也需要资源消耗）





## 分布式限流


**分布式限流**，是为了控制某个应用全局的流量，而非真对单个节点纬度。


### 第一阶段，redis 作为网关的限流策略

**使用 redis 作为限流器**

为了统计某个用户一天内购物车请求的调用量，很容易想到使用 Redis 的 incr 命令，由于 incr 是 Redis 的原子性自增操作，而且 redis 作为分布式服务器的公共存储，可以作为天然的分布式计数器来使用。

每当某个操作发生的时候执行一次 incr 命令。可以设置 key 为 username:day:addcart , 然后执行 incr(key)。


使用redis做限流的缺点：
- redis 限流，每一个请求调用 redis 的 incr 方法，对请求进行计数
- 缺点1：单个大流量的接口，使用 redis 容易产生热点。
- 缺点2：pre-request 模式（就是每次 request 前做一个处理）对性能有一定影响，高频的网络往返。

解决思路：
**从获取单个 quota 升级成批量 quota。quota: 表示速率，获取后使用令牌桶算法来限制。**




### 第二阶段，具体服务批量获取 quota

![分布式限流](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E5%88%86%E5%B8%83%E5%BC%8F%E9%99%90%E6%B5%81%E7%AD%96%E7%95%A5.jpg?raw=true)


- 服务端从 配额管理后台 批量申请 quota
- quota 在本地使用 令牌桶 进行拦截，每次获取的 quota 就是 令牌桶 的令牌产生速率。



具体服务中，对单纯 redis 做限流有了如下的改进：
- 系统的其他服务在每次心跳后，异步向 配额管理后台也就是 TokenServer，批量获取 quota，可以大大减少请求 redis 的频次，获取完以后本地消费，基于令牌桶拦截。
- 初次使用默认值，一旦有过去历史窗口的数据，可以基于历史窗口数据进行 quota 请求。也就是说，第一次配置默认值请求 quota，后面根据滑动串口，计算历史窗口内的 quota 平均值来申请。



缺点：
- 各个服务每次申请的配额需要手动设定静态值略欠灵活，比如每次要20，还是50。
- 经常面临给一组用户划分稀有资源的问题，他们都享有等价的权利来获取资源，但是其中一些用户实际上只需要比其他用户少的资源。也就是资源分配不公平的问题。




解决思路：
- 利用 max-min Fairness 算法来解决 公平分配资源的问题。





### 第三阶段，Token Server 公平配额

一种在实际中广泛使用的分配资源的，分享技术称作**“最大最小公平分享”(Max-Min Fairness)**。

直观上，公平分享分配给每个用户想要的可以满足的最小需求，然后将没有使用的资源均匀的分配给需要‘大资源’的用户。
换句话说，**先把资源公平的分配给每个最小需求的用户，然后将剩余的资源公平的分配给需要大资源的用户。**


最大最小公平分配算法的形式化定义如下：
- 资源按照需求递增的顺序进行分配。
- 不存在用户得到的资源超过自己的需求。
- 未得到满足的用户等价的分享资源。


![Max-Min Fairness算法](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/Max-Min_Fairness%E7%AE%97%E6%B3%95%E7%A4%BA%E4%BE%8B.png?raw=true)


过程：
- 资源总额为 10，有 A、B、C、D 四个服务需要申请资源，并且四个服务申请的最小资源为：2、2.6、4、5
- 根据 Max-Min Fairness算法 平均的思想，首先求均值 10/4 = 2.5，也就是每个资源平均 2.5
- 资源按照从小资源分配开始，那么给 A 分配 2.5 资源，但 A 的最小配额为2，因此只给 2，那么剩余 0.5，留给后面分配
- 给 B,C,D 平均 2.5 再加上 剩余的 0.5 资源的平均 0.5/3, 因此 B,C,D 分配的资源为: 0.5/3 + 2.5 = 2.666，但 B 的最小配额为 2.6，还剩 0.066
- 给C、D 平均分配 0.066/2 + 2.666 = 2.7 ，但 C、D 资源的最小配额都比 2.7大，但是只能能给他们这么多。





**整个服务的流程：**
- Token server 每过 5s 收集一次 各个服务的 心跳
- 然后根据 不同服务 申请的最小配额，利用 Max-Min Fairness 算法 进行分配资源
- 具体服务拿到资源后，利用单机的令牌桶，进行限流



### 第四阶段，不同的服务，设置不同的重要性级别

每个接口配置阈值，运营工作繁重，最简单的我们配置服务级别 quota，更细粒度的，我们可以根据不同重要性设定 quota，我们引入了重要性(criticality):
- **最重要 CRITICAL_PLUS**：为最终的要求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。
- **重要 CRITICAL**：生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题。但是可能没那么严重。
- **可丢弃的 SHEDDABLE_PLUS** ： 这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些请求通常可以过几分钟、几小时后重试。
- **可丢弃的 SHEDDABLE**：这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用。




**gRPC 系统之间，需要自动传递重要性信息**。如果后端接受到请求 A，在处理过程中发出了请求 B 和 C 给其他后端，请求 B 和 C 会使用与 A 相同的重要性属性。


原则：
- 全局配额不足时，优先拒绝低优先级的。
- 全局配额，可以按照重要性分别设置。
- 过载保护时，低优先级的请求先被拒绝。






## 熔断




**断路器(Circuit Breakers)**: 为了限制操作的持续时间，我们可以使用超时，超时可以防止挂起操作并保证系统可以响应。因为我们处于高度动态的环境中，几乎不可能确定在每种情况下都能正常工作的准确的时间限制。断路器以现实世界的电子元件命名，因为它们的行为是都是相同的。断路器在分布式系统中非常有用，因为重复的故障可能会导致雪球效应，并使整个系统崩溃。
服务依赖的资源出现大量错误。

超时的问题：
- 某个用户超过资源配额时，后端任务会快速拒绝请求，返回“配额不足”的错误，但是拒绝回复仍然会消耗一定资源。有可能后端忙着不停发送拒绝请求，导致过载。


熔断器的状态有三种状态：

![熔断器的状态](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%86%94%E6%96%AD%E5%99%A8%E7%8A%B6%E6%80%81%E5%9B%BE.png?raw=true)

- 打开状态 / Open：打开熔断，服务降级
- 关闭状态 / Closed：熔断关闭，服务正常
- 半开状态 / HalfOpen：允许调用，根据调用状态切换熔断状态。例如，允许一个请求，如果请求成功，熔断器切换成关闭装填。





### Google SRE 熔断机制

公式：
```go
max(0, (requests - K*accepts) / (requests + 1))
```

- requests : 表示总请求
- accepts : 表示成功的请求
- K ：表示一个常数系数，一般取2
- 这个公式最终计算出来一个 百分比，例如 0.5，表示可以保留多少流量



SRE 熔断的实现：
```go
func (b *sreBreaker) Allow error {
    success, total := b.stat.Value()
    k := b.k * float64(successs)
    
    if total < b.request || flat64(total) < k {
        return nil
    }
    
    dr := math.Max(0, (float64(total) - k) / (float64(total + 1)) 
    
    rr := b.r.Float64()
    
    if dr <= rr {
        return nil
    }
    
    return ecode.ServiceUnavailable
}
```



## 客户端限流

例如：双十一的时候，大量用户请求，会出现系统繁忙，稍后重试的提示，有时候直接按钮是灰色的不能点击，这就是客户端的限流保护。


positive feedback: 
- 用户总是积极重试，访问一个不可达的服务。
- 客户端需要限制请求频次，retry backoff 做一定的请求退让。例如：一个接口崩溃，移动客户端会限制 3s 内不要再发这个 接口的请求。
- 可以通过接口级别的error_details，挂载到每个 API 返回的响应里。






# 降级

通过降级回复来减少工作量，或者丢弃不重要的请求。而且需要了解哪些流量可以降级，并且有能力区分不同的请求。通常提供降低回复的质量来答复减少所需的计算量或者时间。

自动降级通常需要考虑几个点：
- 确定具体采用哪个指标作为流量评估和优雅降级的决定性指标(如，CPU、延迟、队列长度、线程数量、错误等)。
    - 当 cpu 到达某一个阈值时，执行降级操作
    - 当下游请求返回错误，例如500、504时，执行降级操作
- 当服务进入降级模式时，需要执行什么动作？
    - 降级操作应该足够简单，要么返回空 empty，要么从 local cache 或者 remote cache 捞数据返回
- 流量抛弃或者优雅降级应该在服务的哪一层实现？是否需要在整个服务的每一层都实现，还是可以选择某个高层面的关键节点来实现？
    - 降级通常在 BFF 层，或者 ApiGateway 做



同时我们要考虑一下几点：
- 优雅降级不应该被经常触发 - 通常触发条件现实了容量规划的失误，或者是意外的负载。
- 演练，代码平时不会触发和使用，需要定期针对一小部分的流量进行演练，保证模式的正常。
- 应该足够简单。



## 降级常用的操作



降级本质为: **提供有损服务。**
- UI 模块化，非核心模块降级。
- BFF 层聚合 API，模块降级。
- 页面上一次缓存副本。
- 默认值、热门推荐等。
- 流量拦截 + 定期数据缓存(过期副本策略)。
- 处理策略
- 页面降级、延迟服务、写/读降级、缓存降级
- 抛异常、返回约定协议、Mock 数据、Fallback 处理




# 重试


当请求返回错误(例: 配额不足、超时、内部错误等)，对于 backend  部分节点过载的情况下，倾向于立刻重试，但是需要留意重试带来的流量放大:
- 限制重试次数和基于重试分布的策略(重试比率: 10%)。
- 随机化、指数型递增的重试周期: exponential backoff + jitter。
- client 测记录重试次数直方图，传递到 server，进行分布判定，交由 server 判定拒绝。
- 只应该在失败的这层进行重试，当重试仍然失败，全局约定错误码“过载，无须重试”，避免级联重试。




# 负载均衡

**数据中心内部的负载均衡**

在理想情况下，某个服务的负载会完全均匀地分发给所有的后端任务。在任何时刻，最忙和最不忙的节点永远消耗同样数量的CPU。

**目标：**
- 均衡的流量分发。
- 可靠的识别异常节点。
- scale-out，增加同质节点扩容。
- 减少错误，提高可用性。



后端 backend 之间的 load 差异比较大：
- 每个请求的处理成本不同。
- 物理机环境的差异:
    - 服务器很难强同质性。
    - 存在共享资源争用（内存缓存、带宽、IO等）。
- 性能因素:
    - FullGC。
    - JVM JIT。


参考JSQ（最闲轮训）负载均衡算法带来的问题，缺乏的是服务端全局视图，因此我们目标需要综合考虑：负载+可用性。


如果只考虑轮询，那么一个服务的的请求会轮询的分配给下游服务，但是如果这时下游的服务负载很高，就需要调度到别的节点上。




参考了《The power of two choices in randomized load balancing》的思路，我们使用 the choice-of-2 算法，随机选取的两个节点进行打分，选择更优的节点:
- 选择 backend：CPU，client：health、inflight、latency 作为指标，使用一个简单的线性方程进行打分。
    - 后端 CPU 负载情况
    - client 端的 健康检查情况 health
    - client 端的 请求数量 inflight
    - client 端到 后端的 耗时 latency
- 对新启动的节点使用常量惩罚值(penalty)，以及使用探针方式最小化放量，进行预热。
- 打分比较低的节点，避免进入“永久黑名单”而无法恢复，使用统计衰减的方式，让节点指标逐渐恢复到初始状态(即默认值)。



CPU、health、latency 指标计算结合 moving average（滑动均值），inflight 请求数是一个原子递增。

使用时间衰减，计算vt = v(t-1) * β + at * (1-β) ，β为若干次幂的倒数即: $Math.Exp((-span) / 600ms)$