[toc]


# Goroutine 原理


## Goroutine 定义

**Goroutine 是一个与其他 goroutines 并行运行在同一地址空间的 Go 函数或方法。一个运行的程序由一个或更多个 goroutine 组成。它与线程、协程、进程等不同。它是一个 goroutine**

- Goroutines 在同一个用户地址空间里并行独立执行 functions
- channels 则用于 goroutines 间的通信和同步访问控制。

Goroutine 其实是 Golang 实现的用户态的，使用 Runtime 进行托管维护的一个用于并发的结构体。


**内核态与用户态：**

1. 内核空间与用户空间

对 32 位操作系统而言，它的寻址空间（虚拟地址空间，或叫线性地址空间）为 4G（2的32次方）。也就是说一个进程的最大地址空间为 4G。操作系统的核心是内核(kernel)，它独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。

为了保证内核的安全，现在的操作系统一般都强制用户进程不能直接操作内核。具体的实现方式基本都是由操作系统将虚拟地址空间划分为两部分，一部分为**内核空间**，另一部分为**用户空间**。

每个进程的 4G 地址空间中，最高 1G 都是一样的，即内核空间。只有剩余的 3G 才归进程自己使用。

2. 内核态与用户态

内核态和用户态：
- 内核态：运行在内核空间的进程的状态
- 用户态：运行在用户空间的进程的状态


3. 用户空间到内核空间的切换

所有的系统资源管理都是在内核空间中完成的。比如读写磁盘文件，分配回收内存，从网络接口读写数据等等。

比如应用程序要读取磁盘上的一个文件，它可以向内核发起一个 "系统调用"。先把数据读取到内核空间中，然后再把数据拷贝到用户空间并从内核态切换到用户态


对于一个进程来讲，从用户空间进入内核空间并最终返回到用户空间，这个过程是十分复杂的。

举个例子，比如我们经常接触的概念 "堆栈"，其实进程在内核态和用户态各有一个堆栈。运行在用户空间时进程使用的是用户空间中的堆栈，而运行在内核空间时，进程使用的是内核空间中的堆栈。所以说，**Linux 中每个进程有两个栈，分别用于用户态和内核态。**



**Goroutine 的实现原理**

![Goroutine 实现原理](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/Goroutine%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png?raw=true)



## Goroutine 与 Thread 的区别

1. **内存占用**，创建一个 goroutine 的栈内存消耗为 2 KB(Linux AMD64 Go v1.4后)，运行过程中，如果栈空间不够用，会自动进行扩容。
    - 创建一个 thread 为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存( 1 - 8 MB 栈内存，线程标准 POSIX Thread)
    - 还需要一个被称为 “guard page” 的区域用于和其他 thread 的栈空间进行隔离。就是每一个 线程后会跟一个 guard page 内存区域，区别于下一个线程。避免线程堆栈溢出后操作后面的线程内存。
    - 栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。
2. **创建/销毁**，线程创建和销毀都会有巨大的消耗，是内核级的交互(trap)。
    - POSIX 线程(定义了创建和操纵线程的一套 API)通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。而进入内核调度所消耗的性能代价比较高，开销较大。
    - goroutine 是用户态线程，是由 go runtime 管理，创建和销毁的消耗非常小。
3. **调度切换**，抛开陷入内核，线程切换会消耗 1000-1500 纳秒(上下文保存成本高，较多寄存器，公平性，复杂时间计算统计)，一个纳秒平均可以执行 12-18 条指令。
    - 上下文切换：在进程 A 切换到进程 B 的过程中，先保存 A 进程的上下文，以便于等 A 恢复运行的时候，能够知道 A 进程的下一条指令是啥。然后将要运行的 B 进程的上下文恢复到寄存器中。这个过程被称为上下文切换。
    - 由于线程切换，执行指令的条数会减少 12000-18000。
    - goroutine 的切换约为 200 ns(用户态、3个寄存器)，相当于 2400-3600 条指令。因此，goroutines 切换成本比 threads 要小得多。
4. **复杂性**，线程的创建和退出复杂，多个 thread 间通讯复杂(share memory)。
    - 不能大量创建线程(参考早期的 httpd)，成本高，使用网络多路复用，存在大量callback(参考twemproxy、nginx 的代码)。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入线程池等。
    - Goroutine 创建简单，利用 chan 进行 Goroutine 间通信方便容易管理。




## Goroutine M:N 模型


![Goroutine M:N 模型](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/GoroutineM%E6%AF%94N%E6%A8%A1%E5%9E%8B.png?raw=true)


**M:N模型**

Go 创建 M 个线程(CPU 执行调度的单元，内核的 task_struct)，之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行，即 M:N 模型。

这里的 M 个线程，指的是在内核中创建的 Pthread 线程。每一个线程中，都会依附一些 Gorouine。


**注意：**

- 它们能够同时运行，与线程类似，但相比之下非常轻量。因此，程序运行时，Goroutines 的个数应该是远大于线程的个数的。
- 同一个时刻，一个线程只能跑一个 goroutine。
- 当 goroutine 发生阻塞 (chan 阻塞、mutex、syscall 等等) 时，Go 会把当前的 goroutine 调度走，让其他 goroutine 来继续执行，而不是让线程阻塞休眠，尽可能多的分发任务出去，让 CPU 忙。




# GMP 调度模型


## GMP 概念

- **G : Goroutine**
    - goroutine 的缩写，每次 go func() 都代表一个 G，无限制。
    - 使用 struct runtime.g，包含了当前 goroutine 的状态、堆栈、上下文。
- **M : thread**
    - 工作线程(OS thread)也被称为 Machine，使用 struct runtime.m，所有 M 是有线程栈的。
    - 如果不对该线程栈提供内存的话，系统会给该线程栈提供内存(不同操作系统提供的线程栈大小不同)。
    - 当指定了线程栈，则 M.stack→G.stack，M 的 PC 寄存器指向 G 提供的函数，然后去执行。
    - 也就是说，当执行某个 Goroutine 时，M 的栈会指向这个 G 的栈，寄存器指向 G 的函数来执行，当执行下一个 Goroutine 时，在切换。执行完 G 后，回切回自己 M 的线程栈
- **P : Processor**
    - 它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。
    - “Processor”是一个抽象的概念，并不是真正的物理 CPU。
    - 引入一个结构 P，它代表了 M 所需的上下文环境，也是处理用户级代码逻辑的处理器。
    - 负责衔接 M 和 G 的调度上下文，将等待执行的 G 与 M 对接。
        - 当 P 有任务时需要创建或者唤醒一个 M 来执行它队列里的任务。所以 P/M 需要进行绑定，构成一个执行单元。
        - P 决定了并行任务的数量，可通过 runtime.GOMAXPROCS 来设定。在 Go1.5 之后GOMAXPROCS 被默认设置可用的核数，而之前则默认为1。





## GMP 调度模型




## Go1.2 版本的 GM 调度器

Go 1.2前的调度器实现，限制了 Go 并发程序的伸缩性，尤其是对那些有高吞吐或并行计算需求的服务程序。


![GM 调度器](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/GoroutineGM%E8%B0%83%E5%BA%A6%E5%99%A8%E8%80%81%E7%89%88%E6%9C%AC.png?raw=true)

**过程：**
- 所有需要执行的 Goroutine 都在一个全局的队列 global queue 中
- 当某个线程 M 有空闲时，会从全局队列中取一个 Goroutine 执行，当执行到该 G 中的阻塞代码后，会将 Goroutine 放回 全局队列中
- 当其他线程 M 有空闲时，也会从全局队列中取一个 Goroutine 执行。
- 注意，这里 不同的 M 从全局队列中取 G 时，都需要加锁。


**问题：**
- 单一全局互斥锁(Sched.Lock)和集中状态存储
    - 导致所有 goroutine 相关操作，比如：创建、结束、重新调度等都要上锁。
- Goroutine 传递问题
    - M 经常在 M 之间传递”可运行”的 goroutine，这导致调度延迟增大以及额外的性能损耗（刚创建的 G 放到了全局队列，而不是本地 M 执行，不必要的开销和延迟）。
- Per-M 持有内存缓存 (M.mcache)
    - 每个 M 持有 mcache 和 stack alloc，然而只有在 M 运行 Go 代码时才需要使用的内存(每个 mcache 可以高达2mb)，当 M 在处于 syscall 时并不需要。运行 Go 代码和阻塞在 syscall 的 M 的比例高达1:100，造成了很大的浪费。同时内存亲缘性也较差。G 当前在 M 运 行后对 M 的内存进行了预热，因为现在 G 调度到同一个 M 的概率不高，数据局部性不好。
- 严重的线程阻塞/解锁
    - 在系统调用的情况下，工作线程经常被阻塞和取消阻塞，这增加了很多开销。比如 M 找不到G，此时 M 就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的 G 来执行。




## GMP 调度器


![GMP 调度模型](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/Goroutine%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86GMP.png?raw=true)

**每一个线程 M 对应一个 P，但是 P 的数量是根据系统 CPU 的核数，也就是说，P 跟 M 不是一一对应的，有可能有多个 M 对应同一个P**

**过程：**
- 全局队列（Global Queue）：存放等待运行的 G。
- P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
- P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。
- M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。



**优势：**
- 引入了 local queue，因为 P 的存在，runtime 并不需要做一个集中式的 goroutine 调度，每一个 M 都会在 P's local queue 或 global queue 或者其他 P 队列中找 G 执行，减少全局锁对性能的影响。
- 这也是 GMP Work-stealing 调度算法的核心。注意 P 的本地 G 队列还是可能面临一个并发访问的场景，为了避免加锁，这里 P 的本地队列是一个 LockFree的队列，窃取 G 时使用 CAS 原子操作来完成。关于LockFree 和 CAS 的知识参见 Lock-Free。




# Goroutine 的生命周期


## Go程序的启动

![Go 主程序启动](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/go%E4%B8%BB%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E7%A4%BA%E4%BE%8B.png?raw=true)

**整个程序始于一段汇编，而在随后的 runtime·rt0_go（也是汇编程序）中，会执行很多初始化工作。**

主程序启动的过程：
- 绑定 m0 和 g0，**m0 就是程序的主线程，程序启动必然会拥有一个主线程，这个就是 m0**。**g0 负责调度，即 shedule() 函数**。
- 注意：**每个 M 都有一个 G0 负责调度。**
- **创建 P，绑定 m0 和 p0**，首先会创建 GOMAXPROCS 个 P ，存储在 sched 的 空闲链表(pidle)。
- **新建任务 g 到 p0 本地队列，m0 的 g0 会创建一个 指向 runtime.main() 的 g ，并放到 p0 的本地队列。**
- runtime.main(): 启动 sysmon 线程；启动 GC 协程；执行 init，即代码中的各种 init 函数；执行 main.main 函数





## P 和 M 的创建

1. P 和 M 的创建机制

![程序刚启动时P和M的创建示例](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%A8%8B%E5%BA%8F%E5%88%9A%E5%90%AF%E5%8A%A8%E6%97%B6P%E5%92%8CM%E7%9A%84%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B.png?raw=true)

**过程：**
- 程序运行后，首先会创建 GOMAXPROCS 个 P，将所有的 P 存储在 sched 的空闲列表中
- 创建 M0 并且 与 P0 绑定，M0 中的 G0 会创建 main 的 Goroutine 运行
- 准备运行的新 goroutine 将唤醒 P 以更好地分发工作。这个 P 将创建一个与之关联的 M 绑定到一个 OS thread。
- 当需要有新的 M 创建时，会先检查 M 的空闲列表中有没有可以唤醒的 M，如果有，则唤醒，如果没有，则创建 OS thread



2. 唤醒机制

![P和M的唤醒机制](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%A9%BA%E9%97%B2%E9%98%9F%E5%88%97%E4%B8%AD%E7%9A%84M%E5%94%A4%E9%86%92%E7%A4%BA%E4%BE%8B.png?raw=true)

**过程：**
- **M 的 spinning 状态：当 M 中的 Goroutine 执行完后，会进入 spinning 状态，就是自旋查找可以执行的 Goroutine，如果到一段时间后，就会进入睡眠状态，M 会和 P 解绑，进入到 M 的空闲列表中。**
- 有空闲的 P 而没有在 spinning 状态的 M 时候, 需要去唤醒一个空闲(睡眠)的 M 或者新建一个。
- 当线程首次创建时，会执行一个特殊的 G，即 g0，它负责管理和调度 G。




## G0 特殊的 Goroutine


### G0 的调度过程：

下面是一个 Goroutine 在向 channel 发送数据是阻塞的例子：
```
ch := make(chan int)
[...]
ch <- v
```

**整个调度过程为：**

1. 当在 channel 上阻塞时，当前的 Goroutine ，也就是图中的 G7 会被停放（ parked ），即处于等待状态（ waiting mode ），并且不会被放在任何 Goroutine 队列中：

![G0调度过程1](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/G0%E8%B0%83%E5%BA%A6%E8%BF%87%E7%A8%8B1.png?raw=true)

2. G0 会替换 Goroutine 并进行一轮调度：
    - G0 会在 P 的 local queue 中拿出一个 Goroutine，进行执行
    - 本地队列具有调度的优先级
    - 此时，阻塞的 G7 会被添加到 parked 列表中

![G0调度过程2](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/G0%E8%B0%83%E5%BA%A6%E8%BF%87%E7%A8%8B2.png?raw=true)

3. G0 调度 G2 会被执行:

![G0调度过程3](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/G0%E8%B0%83%E5%BA%A6%E8%BF%87%E7%A8%8B3.png?raw=true)

4. 一旦有接收者读取 channel 中的数据 `v := <-ch`，7 号 Goroutine 就会解除阻塞状态：
    - 收到消息的 Goroutine 会切换到 g0，并且通过放入本地队列的方式将该 Goroutine 从停放状态解锁：

![G0调度过程4](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/G0%E8%B0%83%E5%BA%A6%E8%BF%87%E7%A8%8B4.png?raw=true)

5. 当下次 G0 调度时，就有可能会从本地队列中拿到 G7 进行后续的执行。


### G0 的职责

**G0 基于两种断点将 G 调度到线程上：**

- 当 G 阻塞时：系统调用、互斥锁或 chan。
    - 阻塞的 G 进入睡眠模式/进入队列，并允许 G0 安排和运行等待其他的 G。
- 在函数调用期间，如果 G 必须扩展其堆栈。这个断点允许 G0 调度另一个 G 并避免运行 G 占用CPU。


**G0 的职责：**
- 与常规 G 相反，G0 有一个固定和更大的栈。
- G0 负责 Goroutine 的创建，当调用 `go func(){ ... }()` 或 `go myFunction()` 时，Go 会在把它们放入本地队列前，将函数的创建委托给 g0 去做：
- Defer 函数的分配
- GC 收集，比如 STW、扫描 G 的堆栈和标记、清楚操作
- 栈扩容，当需要的时候，由 g0 进行扩栈操作




## G0 调度 Goroutine 堆栈的切换

在 Go 中，G 的切换相当轻便，其中需要保存的状态仅仅涉及以下两个：
- **Goroutine 在停止运行前执行的指令**，程序当前要运行的指令是记录在程序计数器（PC）中的， G 稍后将在同一指令处恢复运行；
- **G 的堆栈**，以便在再次运行时还原局部变量；


在切换之前，堆栈将被保存，以便在 G 再次运行时进行恢复：

![G0调度Goroutine堆栈的切换](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/G0%E8%B0%83%E5%BA%A6Goroutine%E5%A0%86%E6%A0%88%E7%9A%84%E5%88%87%E6%8D%A2.png?raw=true)



从 G 到 G0 或从 G0 到 G 的切换是相当迅速的，它们只包含少量固定的指令。相反，对于调度阶段，调度程序需要检查许多资源以便确定下一个要运行的 G。

当前 g 阻塞在 chan 上并切换到 g0 的过程：

1. PC 和堆栈指针一起保存在内部结构中；
2. 将 G0 设置为正在运行的 goroutine；
3. G0 的堆栈替换当前堆栈；
4. G0 寻找新的 Goroutine 来运行



# Work-stealing 调度算法



## 调度方式

**有三种调度的方式：**

- 每过 N 轮调度后，P 会从全局队列 global queue 中拿一个 G
- 优先从 P 的本地队列 local queue 中，取 G
- 如果 P 的本地队列中没有可用的 G：
    - 会从其他的 P 的本地队列中 偷(steal) 一些 G
    - 如果其他 P 的本地队列中也没有可用的 G，再回去查看全局队列 global queue 中拿 G
    - 如果都没有，会去检查一些网络的 Goroutine 是否可用，poll network



这种调度方式就是为了避免 Goroutine 饥饿，避免全局队列的 G 饥饿

**全局队列中 G 的添加方式：**

- 新建 G 时 P 的本地 G 队列放不下，已满并达到 256个的时候会放半数 G 到全局队列去
- 阻塞的系统调用返回时找不到空闲 P 也会放到全局队列。



**窃取其他 P 本地队列 G 的公平性：**
- 当一个 P 执行完本地所有的 G 之后，会尝试挑选一个受害者 P，从它的 G 队列中窃取一半的 G。当尝试若干次窃取都失败之后，会从全局队列中获取(当前个数/GOMAXPROCS)个 G。
- 为了保证公平性，**从随机位置上的 P 开始，而且遍历的顺序也随机化了(选择一个小于 GOMAXPROCS，且和它互为质数的步长)，保证遍历的顺序也随机化了。**


互质： 即两个或多个整数的公因数只有1的非零自然数



## 系统调用 syscall

1. 系统调用阻塞时间很短：

![系统调用阻塞时间很短](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8syscall1.png?raw=true)

**过程：**
- 与 P3 绑定的 M 中的某个 G 调用 syscall，造成 M 解绑 P，然后 M 和 G 进入阻塞，而 P 此时的状态就是 syscall，表明这个 P 的 G 正在 syscall 中，这时的 P 是不能被调度给别的 M 的。
- 如果在短时间内阻塞的 M 就唤醒了，那么 M 会优先来重新获取这个 P，能获取到就继续绑回去，这样有利于数据的局部性。




**系统监视器 (system monitor)*，称为 sysmon，会定时扫描。在执行 syscall 时, 如果某个 P 的 G 执行超过一个 sysmon tick(10ms)，就会把他设为 idle，重新调度给需要的 M，强制解绑。






2. 系统调用阻塞时间较长：

![系统调用阻塞时间较长](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8syscall2.png?raw=true)


**过程：**
- P1 和 M 脱离后目前在 idle list 中等待被绑定（处于 syscall 状态）。
- 而 G35 在 syscall 结束后，该 M 按照如下规则执行直到满足其中一个条件： 
    - 优先尝试获取同一个 P(P1)，恢复执行 G
    - 如果时间较长，空闲队列中没有处于 syscall 的 P1，会尝试获取 idle list 中的其他空闲 P，恢复执行 G
    - 如果找不到空闲 P，把 G 放回 global queue，M 放回到 idle list






## M 的 Spining thread

线程自旋是相对于线程阻塞而言的，表象就是循环执行一个指定逻辑(调度逻辑，目的是不停地寻找 G)。

**问题：**
- 如果 G 迟迟不来，CPU 会白白浪费在这无意义的计算上。

**好处：**
- 降低了 M 的上下文切换成本，提高了性能。



**两个地方引入自旋：**
- 类型1：M 不带 P 的找 P 挂载（一有 P 释放就结合）
- 类型2：M 带 P 的找 G 运行（一有 runable 的 G 就执行）

**注意：**
- **为了避免过多浪费 CPU 资源，自旋的 M 最多只允许 GOMAXPROCS (Busy P)。**
- **同时当有类型1的自旋 M 存在时，类型2的自旋 M 就不阻塞，阻塞会释放 P，一释放 P 就马上被类型1的自旋 M 抢走了，没必要。**
- **在新 G 被创建、或 M 进入系统调用、或 M 从空闲被激活这三种状态变化前，调度器会确保至少有一个自旋 M 存在（唤醒或者创建一个 M），除非没有空闲的 P。**
    - 这种情况下，当新 G 创建，如果有可用 P，就意味着新 G 可以被立即执行，即便不在同一个 P 也无妨，所以我们保留一个自旋的 M（这时应该不存在类型1的自旋只有类型2的自旋）就可以保证新 G 很快被运行。
    - 当 M 进入系统调用，意味着 M 不知道何时可以醒来，那么 M 对应的 P 中剩下的 G 就得有新的 M 来执行，所以我们保留一个自旋的 M 来执行剩下的 G（这时应该不存在类型2的自旋只有类型1的自旋）。
    - 如果 M 从空闲变成活跃，意味着可能一个处于自旋状态的 M 进入工作状态了，这时要检查并确保还有一个自旋 M 存在，以防还有 G 或者还有 P 空着的。




## 系统监控 sysmon

**sysmon 也叫监控线程，它无需 P 也可以运行，他是一个死循环，每20us~10ms循环一次，循环完一次就 sleep 一会，为什么会是一个变动的周期呢，主要是避免空转，如果每次循环都没什么需要做的事，那么 sleep 的时间就会加大。**


**监控线程的作用：**
- 释放闲置超过5分钟的 span 物理内存；
- 如果超过2分钟没有垃圾回收，强制执行；
- 将长时间未处理的 netpoll 添加到全局队列；
- 向长时间运行的 G 任务发出抢占调度；
- 收回因 syscall 长时间阻塞的 P；


下面是 sysmon 监控线程处理的过程：

![监控线程处理的过程](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%9B%91%E6%8E%A7%E7%BA%BF%E7%A8%8Bsysmon%E8%BF%87%E7%A8%8B.png?raw=true)


**过程：**
- 当绑定在 P3 的 M 上 G35 执行时间超过10ms，sysmon 调用 preemptone 将 G 标记为 stackPreempt ，也就是可以抢占的。
- 异步抢占，注册 sigurg 信号，通过sysmon 检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。




## Network poller

Go 基于 I/O multiplexing 和 goroutine 构建了一个简洁而高性能的原生网络模型(基于 Go 的 I/O 多路复用 netpoll )，提供了 goroutine-per-connection 这样简单的网络编程模式。


Go netpoll 通过在底层对 epoll/kqueue/iocp 的封装，从而实现了**使用同步编程模式达到异步执行的效果**。总结来说，所有的网络操作都以网络描述符 netFD 为中心实现。netFD 与底层 PollDesc 结构绑定，当在一个 netFD 上读写遇到 EAGAIN 错误时，就将当前 goroutine 存储到这个 netFD 对应的 PollDesc 中，同时调用 gopark 把当前 goroutine 给 park 住，直到这个 netFD 上再次发生读写事件，才将此 goroutine 给 ready 激活重新运行。显然，在底层通知 goroutine 再次发生读写等事件的方式就是 epoll/kqueue/iocp 等事件驱动机制。



也就是：

G 发起网络 I/O 操作也不会导致 M 被阻塞(仅阻塞G)，从而不会导致大量 M 被创建出来。将异步 I/O 转换为阻塞 I/O 的部分称为 netpoller。打开或接受连接都被设置为非阻塞模式。如果你试图对其进行 I/O 操作，并且文件描述符数据还没有准备好，G 会进入 gopark 函数，将当前正在执行的 G 状态保存起来，然后切换到新的堆栈上执行新的 G。




**那什么时候 G 被调度回来呢？**
- sysmon
- schedule()：M 找 G 的调度函数
- GC：start the world

调用 netpoll() 在某一次调度 G 的过程中，处于就绪状态的 fd 对应的 G 就会被调度回来。

G 的 gopark 状态：G 置为 waiting 状态，等待显示 goready 唤醒，在 poller 中用得较多，还有锁、chan 等。