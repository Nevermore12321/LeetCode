# 评论系统结构设计

[toc]



## 简介


1. 功能模块
2. 架构设计
3. 存储设计
4. 可用性设计





## 1. 功能模块

架构设计最重要的就是理解整个产品体系在系统中的定位。搞清楚系统背后的背景，才能做出最佳的设计和抽象。**不要做需求的翻译机，先理解业务背后的本质，事情的初衷。**



评论系统，我们往小里做就是视频评论系统，往大里做就是评论平台，**可以接入各种业务形态**。
- 发布评论: 支持回复楼层、楼中楼。
- 读取评论: 按照时间、热度排序。
- 删除评论: 用户删除、作者删除。
- 管理评论: 作者置顶、后台运营管理(搜索、删除、审核等)。


在动手设计前，反复思考，真正编码的时间只有5%。



## 2. 架构设计

**评论系统的架构设计如下图：**
![评论系统的架构](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png?raw=true)


分层简介：
- **BFF: comment**
    - 复杂评论业务的服务编排，比如访问账号服务进行等级判定，同时需要在 BFF 面向移动端/WEB场景来设计 API
    - 这一层抽象把评论的本身的内容列表处理(加载、分页、排序等)进行了隔离，关注在业务平台化逻辑上。
    - 这一层主要是业务逻辑的处理，比如评论的 topic 对不对，请求的用户 id 有没有权限等等，而与数据库的CURD操作，专门一层来负责。
- **Service: comment-service**
    - 服务层，去平台业务的逻辑，专注在评论功能的 API 实现上，比如发布、读取、删除等，
    - 关注在稳定性、可用性上，这样让上游可以灵活组织逻辑把基础能力和业务能力剥离。
    - 这一层，就是专注在 评论API 的实现，对评论的读取、删除、写入等等。
- **Job: comment-job**
    - 消息队列的最大用途是消峰处理，
- **Admin: comment-admin**
    - 管理平台，按照安全等级划分服务，尤其划分运营平台，他们会共享服务层的存储层(MySQL、Redis)。
    - 运营体系的数据大量都是检索，我们使用 canal 进行同步到 ES 中，整个数据的展示都是通过 ES，再通过业务主键更新业务数据层，这样运营端的查询压力就下方给了独立的 fulltext search 系统。
- **Dependency: account-service、filter-service**
    - 整个评论服务还会依赖一些外部 gRPC 服务，统一的平台业务逻辑在 comment BFF 层收敛
    - 这里 account-service 主要是账号服务，filter-service 是敏感词过滤服务。
    


**架构设计等同于数据设计，梳理清楚数据的走向和逻辑。尽量避免环形依赖、数据双向请求等。**



### 1. comment-service

comment-service，专注在评论数据处理(认真想下 Separation of Concerns)。


我们一开始是 comment-service 和 comment 是一层，业务耦合和功能耦合在一起，非常不利于迭代，当然在设计层面可以考虑目录结构进行拆分，但是架构层次来说，迭代隔离也是好的。

**读的核心逻辑:** 

- **Cache-Aside 模式**，先读取缓存，再读取存储。早期 cache rebuild 是做到服务里的，对于重建逻辑，一般会使用 read ahead 的思路，即预读，用户访问了第一页，很有可能访问第二页，所以缓存会超前加载，避免频繁 cache miss。
- 当缓存抖动，特别容易引起集群 thundering herd 现象，大量的请求会触发 cache rebuild，因为使用了预加载，容易导致服务OOM。
- 所以我们看到回源的逻辑里，我们使用了消息队列来进行逻辑异步化，对于当前请求只返回 mysql 中部分数据即止。
- 也就是说，如果有缓存抖动，或者 cache miss，comment-service 服务会写一条指令到 kafka 中，也就是回源请求，让 comment-job 服务来rebuild cache，这样会减轻 mysql 的压力，使得大量的 请求 在 kafka 中。

**写的核心逻辑: **

- 写和读相比较，写可以认为是透穿到存储层的，系统的瓶颈往往就来自于存储层，或者有状态层。
- 对于写的设计上，我们认为刚发布的评论有极短的延迟(通常小于几 ms)对用户可见是可接受的
- 把对存储的直接冲击下放到消息队列，按照消息反压的思路，即如果存储 latency 升高，消费能力就下降，自然消息容易堆积，系统始终以最大化方式消费。
- Kafka 是存在 partition 概念的，可以认为是物理上的一个小队列，一个 topic 是由一组 partition 组成的，所以 Kafka 的吞吐模型理解为: 全局并行，局部串行的生产消费方式。
- 对于入队的消息，可以按照 hash(comment_subject) % N(partitions) 的方式进行分发。那么某个 partition 中的 评论主题的数据一定都在一起，这样方便我们串行消费。



### 2. comment-admin

comment-admin 是面向运营端的服务。

- mysql binlog 中的数据被 canal 中间件流式消费，获取到业务的原始 CRUD 操作，需要回放录入到 es 中，但是 es 中的数据最终是面向运营体系提供服务能力，需要检索的数据维度比较多
- 在入 es 前需要做一个异构的 joiner，把单表变宽预处理好 join 逻辑，然后倒入到 es 中。
- 一般来说，运营后台的检索条件都是组合的，使用 es 的好处是避免依赖 mysql 来做多条件组合检索，同时 mysql 毕竟是 oltp 面向线上联机事务处理的。通过冗余数据的方式，使用其他引擎来实现。
- es 一般会存储检索、展示、primary key 等数据，当我们操作编辑的时候，找到记录的 primary key，最后交由 comment-admin 进行运营测的 CRUD 操作。


我们内部运营体系基本都是基于 es 来完成的。


### 3. comment

- comment 作为 BFF，是面向端，面向平台，面向业务组合的服务。所以平台扩展的能力，我们都在 comment 服务来实现，方便统一和准入平台，以统一的接口形式提供平台化的能力。
- 依赖其他 gRPC 服务，整合统一平台侧的逻辑(比如发布评论用户等级限定)。
- 直接向端上提供接口，提供数据的读写接口，甚至可以整合端上，提供统一的端上 SDK。也就是说无论什么页面都可以调用这套统一的评论API，来展示。
- 需要对非核心依赖的 gRPC 服务进行降级，当这些服务不稳定时。




## 3. 存储设计

### 存储设计 - 数据库设计


存储设计 - 数据库设计如下图：
![数据库设计](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1.png?raw=true)


comment-subject 数据字段：
- obj_id 和 obj_type 就是接入品论系统的类型，比如文章，视频等。
- member_id：作者用户id
- count：楼层
- root_count：根评论总数

comment_index 数据字段：
- root：根评论
- parent：上级评论
- count：子评论总数
- root_count：根评论总数

comment-content 数据字段：
- comment_id: 对应 comment_index 的id，使用自己的发号器，全局唯一
- at_member_ids：@用户的功能
- device：设备id


将索引表 comment_index 和 内容表 comment_index 分开的原因：
- 因为评论内容有可能很长，也就是内容表的一行数据很大，mysql 的data page 是16K，每次取出的数量有限
- 而索引表很小，一次io可以取出很多条数据。





**数据写入:**
- 事务更新 comment_subject，comment_index，comment_content 三张表
- 其中 content 属于非强制需要一致性考虑的。可以先写入 content，之后事务更新其他表。
- 即便 content 先成功，后续失败仅仅存在一条 ghost 数据。


**数据读取:**
- 基于 obj_id + obj_type 在 comment_index 表找到评论列表，WHERE root = 0 ORDER BY floor。也就是找到所有的按顺序的跟楼层。
- 之后根据 comment_index 的 id 字段捞出 comment_content 的评论内容。
- 对于二级的子楼层，WHERE parent/root IN (id...)。

因为产品形态上只存在二级列表，因此只需要迭代查询两次即可。对于嵌套层次多的，产品上，可以通过二次点击支持。
是不是可以 Graph 存储？DGraph、HugeGraph 类似的图存储思路。



- comment_index: 评论楼层的索引组织表，实际并不包含内容。
- comment_content: 评论内容的表，包含评论的具体内容。其中 comment_index 的 id 字段和 comment_content 是1对1的关系，这里面包含几种设计思想。
    - 表都有主键，即 cluster index，是物理组织形式存放的，comment_content 没有 id，是为了减少一次     二级索引查找，直接基于主键检索，同时 comment_id 在写入要尽可能的顺序自增。
    - 索引、内容分离，方便 mysql datapage 缓存更多的 row，如果和 context 耦合，会导致更大的 IO。长远来看 content 信息可以直接使用 KV storage 存储。




### 存储设计 - 缓存设计

![缓存设计](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/redis%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E8%A1%A8.png?raw=true)




- comment_subject_cache: 
    - 对应主题的缓存，value 使用 protobuf 序列化的方式存入。我们早期使用 memcache 来进行缓存，因为 redis 早期单线程模型，吞吐能力不高。
- comment_index_cache: 
    - 使用 redis sortedset 进行索引的缓存，索引即数据的组织顺序，而非数据内容。
    - 参考过百度的贴吧，他们使用自己研发的拉链存储来组织索引，我认为 mysql 作为主力存储，利用 redis 来做加速完全足够，
    - 对于 cache miss 的构建，我们前面讲过使用kafka的消费者中处理，预加载少量数据，通过增量加载的方式逐渐预热填充缓存，
    - 而 redis sortedset skiplist 的实现，可以做到 O(logN) + O(M) 的时间复杂度，效率很高。
    - sorted set 是要增量追加的，因此必须判定 key 存在，才能 zdd。
- comment_content_cache: 
    - 对应评论内容数据，使用 protobuf 序列化的方式存入。类似的我们早期使用 memcache 进行缓存。


总体思路：**增量加载 + lazy 加载**
- 增量加载：sortedSet 追加，增量
- lazy加载：如果出现cache miss，那么就只加载当前页的往后几页即可，不需要全加载



**搜索流程**
1. 先从缓存中拉取主题，也就是从 comment_subject_cache 中拿到主题，判断主题是否封禁等业务操作。
2. 拉取评论内容，类似游标的概念，上一次评论拉取到什么位置，下次从这个位置的下一个开始拉取。
3. 加载内容，由于每页是有一个范围的，所以每次从comment_index_cache中批量数据，mget，也就是pipeline。


**注意点：**
- 在 comment_index_cache 的 soredSet 中追加数据时，先判断 Exist 是否存在，然后 zadd 追加
- 这样做有一个问题，在判断Exist时，是存在的，在追加时，这个key有可能就会过期，或者消失，这样就会导致这个 sortset 中只有一条数据，以前数据都消失或者过期了
- 解决方法：使用 Expire 代替 Exist，先续期，这样安全一点。




## 4. 可用性设计

### Singleflight 处理缓存击穿

singleflight 包主要是用来做并发控制，整个包的核心代码不到100行，充分利用到了map 和 WaitGroup 的特性。
https://pkg.go.dev/golang.org/x/sync/singleflight

**缓存击穿**  
缓存击穿：缓存在某个时间点过期的时候，恰好在这个时间点对这个 Key 有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。


- 对于热门的主题，如果存在缓存穿透的情况，会导致大量的同进程、跨进程的数据回源到存储层，可能会引起存储过载的情况
- 解决：使用归并回源的思路，也就是只有一个 Goroutine 去回源设置缓存，其他 Goroutine 等待。

**步骤**
- 同进程只交给一个人去获取 mysql 数据，然后批量返回。
- 同时这个 lease owner 投递一个 kafka 消息，做 index cache 的 recovery 操作。
- 这样可以大大减少 mysql 的压力，以及大量透穿导致的密集写 kafka 的问题。
- 更进一步的，后续连续的请求，仍然可能会短时 cache miss，我们可以在进程内设置一个 short-lived flag，标记最近有一个人投递了 cache rebuild 的消息，直接 drop。




**singleflight常用的方法：**
```
func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool)

func (g *Group) DoChan(key string, fn func() (interface{}, error)) <-chan Result

func (g *Group) Forget(key string)
```
- **Do方法**，接受一个字符串 Key 和一个待调用的函数，会返回调用函数的结果和错误。使用 Do 方法的时候，它会根据提供的 Key 判断是否去真正调用 fn 函数。同一个 key，在同一时间只有第一次调用 Do 方法时才会去执行 fn 函数，其他并发的请求会等待调用的执行结果。
- **DoChan方法**：类似 Do 方法，只不过是一个异步调用。它会返回一个通道，等 fn 函数执行完，产生了结果以后，就能从这个 chan 中接收这个结果。
- **Forget方法**：在 SingleFlight 中删除一个 Key。这样一来，之后这个 Key 的 Do 方法调用会执行 fn 函数，而不是等待前一个未完成的 fn 函数的结果。



简单示例：
```
package main

import (
	"errors"
	"golang.org/x/sync/singleflight"
	"log"
	"sync"
)



var g singleflight.Group
var errorNotExist = errors.New("not exist")



func getData(key string) (interface{}, interface{}) {
	//  先读缓存
	data, err := getDataFromCache(key)
	if err == errorNotExist {
		//  缓存中没有，读数据库
		value, err, _ := g.Do(key, func() (interface{}, error) {
			return getDataFromDB(key)
		})
		if err != nil {
			log.Println(err)
			return "", err
		}
		//TOOD: set cache
		data = value.(string)
	} else if err != nil {
		return "", err
	}
	return data, nil

}

// 模拟从cache中获取值，cache中无该值
func getDataFromCache(key string) (string, error) {
	return "", errorNotExist
}

// 模拟从数据库中获取值
func getDataFromDB(key string) (string, error) {
	log.Printf("get %s from database", key)
	return "data", nil
}


//  main函数中默契启动 10 个 Goroutine 去读缓存，并且模拟缓存不存在直接去读 database
func main() {
	var wg sync.WaitGroup
	wg.Add(10)

	//模拟10个并发
	for i := 0; i < 10; i++ {
		go func() {
			defer wg.Done()
			data, err := getData("key")
			if err != nil {
				log.Print(err)
				return
			}
			log.Println(data)
		}()
	}
	wg.Wait()
}

```

执行结果为：
- 可以看到只有一个 Goroutine 执行了 从数据库中读取数据
```bash
2021/05/06 15:42:14 get key from database
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
2021/05/06 15:42:15 data
```


**singleflight包的 Do 方法源码分析**
```go
type Group struct {
	mu sync.Mutex       // protects m
	m  map[string]*call // lazily initialized
}

//  Do 方法，需要传入 key 的值，并且传入一个方法，这个方法也就是 缓存丢失后，去数据库读取的操作
func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) {
	//  加锁
	g.mu.Lock()
	if g.m == nil {
		g.m = make(map[string]*call)
	}
	//  判断 group 中维护了一份 map，如果 map 中已经有了这个key，表示已经有 Goroutine 去都数据库了，当前这个Goroutine就不需要了
	if c, ok := g.m[key]; ok {
		c.dups++
		g.mu.Unlock()
		c.wg.Wait()

		if e, ok := c.err.(*panicError); ok {
			panic(e)
		} else if c.err == errGoexit {
			runtime.Goexit()
		}
		return c.val, c.err, true
	}
	//  如果 map 中没有key，那么就需要执行 传入的 fn 方法，去读取，并且把 key 添加进 map中
	c := new(call)
	c.wg.Add(1)
	g.m[key] = c
	g.mu.Unlock()

	g.doCall(c, key, fn)
	return c.val, c.err, c.dups > 0
}

```


### 热点处理



![热点处理](https://github.com/Nevermore12321/LeetCode/blob/blog/go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/%E7%83%AD%E7%82%B9%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.png?raw=true)

流量热点是因为突然热门的主题，被高频次的访问，因为底层的 cache 设计，一般是按照主题 key 进行一致性 hash 来进行分片，但是热点 key 一定命中某一个节点，这时候 remote cache 可能会变为瓶颈，因此做 cache 的升级 local cache 是有必要的，我们一般使用单进程自适应发现热点的思路，附加一个短时的 ttl local cache，可以在进程内吞掉大量的读请求。

在内存中使用 hashmap 统计每个 key 的访问频次，这里可以使用滑动窗口统计，即每个窗口中，维护一个 hashmap，之后统计所有未过去的 bucket，汇总所有 key 的数据。
之后使用小堆计算 TopK 的数据，自动进行热点识别。